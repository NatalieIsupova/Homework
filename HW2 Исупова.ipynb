{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam vs. Ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целью данного задания является научится отличать письма со спамом "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 1 (2 балла). Чтение данных ** \n",
    "\n",
    "Прочитайте данные из файла spam.csv используя средства модуля [pandas](https://pandas.pydata.org/). В первом столбце пометка о роде письма (spam/ham). Будем считать, что все письма с пометкой spam лежать в первом классе, а остальные в нулевом. Во второй колонке текст сообщения. Отобразите таблицу в следующем виде\n",
    "![example](table_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#чтение\n",
    "df = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')[['v2','v1']]\n",
    "\n",
    "#переименовка колонок\n",
    "df = df.rename(columns={'v1': 'class', 'v2':'text'})\n",
    "df = df[['text', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class\n",
       "0     Go until jurong point, crazy.. Available only ...     0\n",
       "1                         Ok lar... Joking wif u oni...     0\n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3     U dun say so early hor... U c already then say...     0\n",
       "4     Nah I don't think he goes to usf, he lives aro...     0\n",
       "5     FreeMsg Hey there darling it's been 3 week's n...     1\n",
       "6     Even my brother is not like to speak with me. ...     0\n",
       "7     As per your request 'Melle Melle (Oru Minnamin...     0\n",
       "8     WINNER!! As a valued network customer you have...     1\n",
       "9     Had your mobile 11 months or more? U R entitle...     1\n",
       "10    I'm gonna be home soon and i don't want to tal...     0\n",
       "11    SIX chances to win CASH! From 100 to 20,000 po...     1\n",
       "12    URGENT! You have won a 1 week FREE membership ...     1\n",
       "13    I've been searching for the right words to tha...     0\n",
       "14                  I HAVE A DATE ON SUNDAY WITH WILL!!     0\n",
       "15    XXXMobileMovieClub: To use your credit, click ...     1\n",
       "16                           Oh k...i'm watching here:)     0\n",
       "17    Eh u remember how 2 spell his name... Yes i di...     0\n",
       "18    Fine if thatåÕs the way u feel. ThatåÕs the wa...     0\n",
       "19    England v Macedonia - dont miss the goals/team...     1\n",
       "20            Is that seriously how you spell his name?     0\n",
       "21    IÛ÷m going to try for 2 months ha ha only joking     0\n",
       "22    So Ì_ pay first lar... Then when is da stock c...     0\n",
       "23    Aft i finish my lunch then i go str down lor. ...     0\n",
       "24    Ffffffffff. Alright no way I can meet up with ...     0\n",
       "25    Just forced myself to eat a slice. I'm really ...     0\n",
       "26                       Lol your always so convincing.     0\n",
       "27    Did you catch the bus ? Are you frying an egg ...     0\n",
       "28    I'm back &amp; we're packing the car now, I'll...     0\n",
       "29    Ahhh. Work. I vaguely remember that! What does...     0\n",
       "...                                                 ...   ...\n",
       "5542           Armand says get your ass over to epsilon     0\n",
       "5543             U still havent got urself a jacket ah?     0\n",
       "5544  I'm taking derek &amp; taylor to walmart, if I...     0\n",
       "5545      Hi its in durban are you still on this number     0\n",
       "5546         Ic. There are a lotta childporn cars then.     0\n",
       "5547  Had your contract mobile 11 Mnths? Latest Moto...     1\n",
       "5548                 No, I was trying it all weekend ;V     0\n",
       "5549  You know, wot people wear. T shirts, jumpers, ...     0\n",
       "5550        Cool, what time you think you can get here?     0\n",
       "5551  Wen did you get so spiritual and deep. That's ...     0\n",
       "5552  Have a safe trip to Nigeria. Wish you happines...     0\n",
       "5553                        Hahaha..use your brain dear     0\n",
       "5554  Well keep in mind I've only got enough gas for...     0\n",
       "5555  Yeh. Indians was nice. Tho it did kane me off ...     0\n",
       "5556  Yes i have. So that's why u texted. Pshew...mi...     0\n",
       "5557  No. I meant the calculation is the same. That ...     0\n",
       "5558                             Sorry, I'll call later     0\n",
       "5559  if you aren't here in the next  &lt;#&gt;  hou...     0\n",
       "5560                  Anything lor. Juz both of us lor.     0\n",
       "5561  Get me out of this dump heap. My mom decided t...     0\n",
       "5562  Ok lor... Sony ericsson salesman... I ask shuh...     0\n",
       "5563                                Ard 6 like dat lor.     0\n",
       "5564  Why don't you wait 'til at least wednesday to ...     0\n",
       "5565                                       Huh y lei...     0\n",
       "5566  REMINDER FROM O2: To get 2.50 pounds free call...     1\n",
       "5567  This is the 2nd time we have tried 2 contact u...     1\n",
       "5568              Will Ì_ b going to esplanade fr home?     0\n",
       "5569  Pity, * was in mood for that. So...any other s...     0\n",
       "5570  The guy did some bitching but I acted like i'd...     0\n",
       "5571                         Rofl. Its true to its name     0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проводим замену в классах\n",
    "df.loc[df['class'] == 'ham', 'class'] = '0'\n",
    "df.loc[df['class'] == 'spam', 'class'] = '1'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Задача 2 (3 балла). Предобработка ** \n",
    "\n",
    "Перевидите все буквы в нижний регистр. \n",
    "\n",
    "С помошью [регулярных выражений](https://docs.python.org/2/library/re.html) почистите текст отставляя только слова (удалите знаки припенания, а также все числа можно заменить на N и т.п.). \n",
    "\n",
    "Оформите это в виде функции, которая принимает на вход некоторый список текстов и возвращает, соответственно, предобработанный список текстов. \n",
    "\n",
    "Преобразуйте таблицу с данными, так чтобы в ней содержались предобработанные тексты (далее мы будем работать только с ними)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predobrabotka(a):\n",
    "    return [re.findall(r'\\w+', i.lower()) for i in a]\n",
    "\n",
    "df['text'] = predobrabotka(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 3 (3 балла). Формирование словаря** \n",
    "\n",
    "Сформируйте словарь, ключами которого являются слова встречающееся в тексте, а значениями -- колличество раз, которое они встретились в корпусе текста. \n",
    "\n",
    "Оформите это в виде функции, которая принимает на вход список текстов и возвращает словарь. \n",
    "\n",
    "Какой размер словаря вы получили?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина словаря - 8713\n"
     ]
    }
   ],
   "source": [
    "def slovar(a):\n",
    "    dictionary = {}\n",
    "    for i in a:\n",
    "        for word in i:\n",
    "            dictionary.setdefault(word, 0)\n",
    "            dictionary[word] += 1\n",
    "    return dictionary\n",
    "\n",
    "df_dictionary = slovar(df['text'])\n",
    "print('Длина словаря -', len(df_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 4 (2 балла). Удаление стоп-слов** \n",
    "\n",
    "Отсортируйте слова по убыванию частоты их встречаемости в текстах. \n",
    "\n",
    "С помощью модуля [matplotlib.pyplot](https://matplotlib.org/api/pyplot_api.html) постройте график частот встречаемости слов в тексте. \n",
    "\n",
    "Распечатайте топ-10 слов и их частоты. \n",
    "\n",
    "Какие слова чаще всего встречаются в тексте? Значимые ли это слова? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#отсортируем по убыванию\n",
    "dictionary_sort = sorted(df_dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "df_dictionary_sort = pd.DataFrame(data = dictionary_sort, columns=['Word', 'Quantity'])\n",
    "\n",
    "\n",
    "#выберем топ-10 по частоте\n",
    "top10 = dictionary_sort[:10]\n",
    "df_top10 = pd.DataFrame(data = top10, columns=['Word', 'Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>me</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Quantity\n",
       "0    i      3001\n",
       "1   to      2242\n",
       "2  you      2240\n",
       "3    a      1433\n",
       "4  the      1328\n",
       "5    u      1192\n",
       "6  and       979\n",
       "7   in       898\n",
       "8   is       890\n",
       "9   me       802"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего встречаются местоимения, артикли, союзы и предлоги. Это не значимые слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa545438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa519ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#нарисуем график топ-10 по алфавиту\n",
    "df_top10.groupby('Word').sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 5 (5 баллов). Функциия предобработки и удаление стоп-слов. ** \n",
    "\n",
    "Для удаления стоп-слов можно использовать модуль [nltk](http://www.nltk.org/). Импортируйте stopwords из nltk.corpus, далее чтобы получить список английских стоп-слов нужно сделать stopwords.words('english').\n",
    "\n",
    "Перепишите функцию предобрабитки так, чтобы она на вход принимала список текстов и список стоп-слов, чистела текст (в том числе удаляла стоп-слова), возвращала список предобработанных текстов.  \n",
    "\n",
    "Преобразуйте таблицу с данными, так чтобы в ней содержались новые предобработанные тексты (далее мы будем работать только с ними). \n",
    "\n",
    "Сформируйте словарь. \n",
    "\n",
    "Постройте график частот встречаемости слов в тексте. \n",
    "\n",
    "Распечатайте топ-10 слов и их частоты. \n",
    "\n",
    "Какой размер словаря вы получили теперь? Остались ли ещё высокочастотные неинформативные слова? Что это за слова? Добавте их в список стоп-слов и повторите процедуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "print(len(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#чтение\n",
    "df = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')[['v2','v1']]\n",
    "\n",
    "#переименовка колонок\n",
    "df = df.rename(columns={'v1': 'class', 'v2':'text'})\n",
    "df = df[['text', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#проводим замену в классах\n",
    "df.loc[df['class'] == 'ham', 'class'] = '0'\n",
    "df.loc[df['class'] == 'spam', 'class'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predobrabotka_new(a, b):\n",
    "    x = [re.findall(r'\\w+', i.lower()) for i in a] \n",
    "    x = [[word   for word in line if len(word) >= 3] for line in x] #почистила от неинформативных слов длиной менее 3\n",
    "    return [[word   for word in line if word not in b] for line in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jurong, point, crazy, available, bugis, great...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lar, joking, wif, oni]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[free, entry, wkly, comp, win, cup, final, tkt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dun, say, early, hor, already, say]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[freemsg, hey, darling, week, word, back, like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[winner, valued, network, customer, selected, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[mobile, months, entitled, update, latest, col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[gonna, home, soon, want, talk, stuff, anymore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[six, chances, win, cash, 100, 000, pounds, tx...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[urgent, week, free, membership, 100, 000, pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[searching, right, words, thank, breather, pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[watching]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[remember, spell, name, yes, naughty, make, wet]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[fine, thatåõs, way, feel, thatåõs, way, gota]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[england, macedonia, dont, miss, goals, team, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[seriously, spell, name]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[going, try, months, joking]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[pay, first, lar, stock, comin]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[aft, finish, lunch, str, lor, ard, smth, lor,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[ffffffffff, alright, way, meet, sooner]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[forced, eat, slice, really, hungry, tho, suck...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[lol, always, convincing]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[catch, bus, frying, egg, make, tea, eating, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[back, amp, packing, car, let, know, room]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[ahhh, work, vaguely, remember, feel, like, lol]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>[armand, says, get, ass, epsilon]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>[still, havent, got, urself, jacket]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>[taking, derek, amp, taylor, walmart, back, ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>[durban, still, number]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>[lotta, childporn, cars]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>[contract, mobile, mnths, latest, motorola, no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>[trying, weekend]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>[know, wot, people, wear, shirts, jumpers, hat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>[cool, time, think, get]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>[wen, get, spiritual, deep, great]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>[safe, trip, nigeria, wish, happiness, soon, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>[hahaha, use, brain, dear]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>[well, keep, mind, got, enough, gas, one, roun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>[yeh, indians, nice, tho, kane, bit, shud, dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>[yes, texted, pshew, missing, much]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>[meant, calculation, units, school, really, ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>[sorry, call, later]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>[next, hours, imma, flip, shit]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>[anything, lor, juz, lor]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>[get, dump, heap, mom, decided, come, lowes, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>[lor, sony, ericsson, salesman, ask, shuhui, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>[ard, like, dat, lor]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>[wait, til, least, wednesday, see, get]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>[huh, lei]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>[reminder, get, pounds, free, call, credit, de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>[2nd, time, tried, contact, 750, pound, prize,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>[going, esplanade, home]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class\n",
       "0     [jurong, point, crazy, available, bugis, great...     0\n",
       "1                               [lar, joking, wif, oni]     0\n",
       "2     [free, entry, wkly, comp, win, cup, final, tkt...     1\n",
       "3                  [dun, say, early, hor, already, say]     0\n",
       "4        [nah, think, goes, usf, lives, around, though]     0\n",
       "5     [freemsg, hey, darling, week, word, back, like...     1\n",
       "6     [even, brother, like, speak, treat, like, aids...     0\n",
       "7     [per, request, melle, melle, oru, minnaminungi...     0\n",
       "8     [winner, valued, network, customer, selected, ...     1\n",
       "9     [mobile, months, entitled, update, latest, col...     1\n",
       "10    [gonna, home, soon, want, talk, stuff, anymore...     0\n",
       "11    [six, chances, win, cash, 100, 000, pounds, tx...     1\n",
       "12    [urgent, week, free, membership, 100, 000, pri...     1\n",
       "13    [searching, right, words, thank, breather, pro...     0\n",
       "14                                       [date, sunday]     0\n",
       "15    [xxxmobilemovieclub, use, credit, click, wap, ...     1\n",
       "16                                           [watching]     0\n",
       "17     [remember, spell, name, yes, naughty, make, wet]     0\n",
       "18       [fine, thatåõs, way, feel, thatåõs, way, gota]     0\n",
       "19    [england, macedonia, dont, miss, goals, team, ...     1\n",
       "20                             [seriously, spell, name]     0\n",
       "21                         [going, try, months, joking]     0\n",
       "22                      [pay, first, lar, stock, comin]     0\n",
       "23    [aft, finish, lunch, str, lor, ard, smth, lor,...     0\n",
       "24             [ffffffffff, alright, way, meet, sooner]     0\n",
       "25    [forced, eat, slice, really, hungry, tho, suck...     0\n",
       "26                            [lol, always, convincing]     0\n",
       "27    [catch, bus, frying, egg, make, tea, eating, m...     0\n",
       "28           [back, amp, packing, car, let, know, room]     0\n",
       "29     [ahhh, work, vaguely, remember, feel, like, lol]     0\n",
       "...                                                 ...   ...\n",
       "5542                  [armand, says, get, ass, epsilon]     0\n",
       "5543               [still, havent, got, urself, jacket]     0\n",
       "5544  [taking, derek, amp, taylor, walmart, back, ti...     0\n",
       "5545                            [durban, still, number]     0\n",
       "5546                           [lotta, childporn, cars]     0\n",
       "5547  [contract, mobile, mnths, latest, motorola, no...     1\n",
       "5548                                  [trying, weekend]     0\n",
       "5549  [know, wot, people, wear, shirts, jumpers, hat...     0\n",
       "5550                           [cool, time, think, get]     0\n",
       "5551                 [wen, get, spiritual, deep, great]     0\n",
       "5552  [safe, trip, nigeria, wish, happiness, soon, c...     0\n",
       "5553                         [hahaha, use, brain, dear]     0\n",
       "5554  [well, keep, mind, got, enough, gas, one, roun...     0\n",
       "5555  [yeh, indians, nice, tho, kane, bit, shud, dri...     0\n",
       "5556                [yes, texted, pshew, missing, much]     0\n",
       "5557  [meant, calculation, units, school, really, ex...     0\n",
       "5558                               [sorry, call, later]     0\n",
       "5559                    [next, hours, imma, flip, shit]     0\n",
       "5560                          [anything, lor, juz, lor]     0\n",
       "5561  [get, dump, heap, mom, decided, come, lowes, b...     0\n",
       "5562  [lor, sony, ericsson, salesman, ask, shuhui, s...     0\n",
       "5563                              [ard, like, dat, lor]     0\n",
       "5564            [wait, til, least, wednesday, see, get]     0\n",
       "5565                                         [huh, lei]     0\n",
       "5566  [reminder, get, pounds, free, call, credit, de...     1\n",
       "5567  [2nd, time, tried, contact, 750, pound, prize,...     1\n",
       "5568                           [going, esplanade, home]     0\n",
       "5569                          [pity, mood, suggestions]     0\n",
       "5570  [guy, bitching, acted, like, interested, buyin...     0\n",
       "5571                                 [rofl, true, name]     0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = predobrabotka_new(df['text'], stop)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина нового словаря - 8253\n"
     ]
    }
   ],
   "source": [
    "df_dictionary = slovar(df['text'])\n",
    "print('Длина нового словаря -', len(df_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#отсортируем по убыванию\n",
    "dictionary_sort = sorted(df_dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "df_dictionary_sort = pd.DataFrame(data = dictionary_sort, columns=['Word', 'Quantity'])\n",
    "\n",
    "\n",
    "#выберем топ-10 по частоте\n",
    "top10 = dictionary_sort[:10]\n",
    "df_top10 = pd.DataFrame(data = top10, columns=['Word', 'Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>know</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>got</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>come</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Quantity\n",
       "0  call       591\n",
       "1   get       391\n",
       "2  free       284\n",
       "3  know       261\n",
       "4  like       245\n",
       "5  good       245\n",
       "6   got       239\n",
       "7   day       229\n",
       "8  come       229\n",
       "9  time       220"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 6 (5 баллов). Удаление низко частотных слов** \n",
    "\n",
    "По сформированому на предыдущем шаге словарю, посмотрите какой процент слов встречается больше одного раза. Нужны ли нам слова которые встретились только один раз? \n",
    "\n",
    "Преобразуйте функцию предобработки таким образом, что бы в ней, кроме всего прочего, формировался словарь и удалялись слишком редкие слова. \n",
    "\n",
    "Преобразуйте таблицу с данными, так чтобы в ней содержались новые предобработанные тексты (далее мы будем работать только с ними). \n",
    "\n",
    "Сформируйте словарь. Каков размер словаря теперь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент слов, встречающихся 1 раз -  51.859929722525145\n"
     ]
    }
   ],
   "source": [
    "#каков процент слов, встречающихся более 1 раза\n",
    "\n",
    "dictionary_1time = df_dictionary_sort[df_dictionary_sort['Quantity'] == df_dictionary_sort['Quantity'].min()]\n",
    "\n",
    "print('Процент слов, встречающихся 1 раз - ', len(dictionary_1time)*100/len(df_dictionary_sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predobrabotka_new_new(a, b):\n",
    "    x = [re.findall(r'\\w+', i.lower()) for i in a] \n",
    "    x = [[word   for word in line if len(word) >= 3] for line in x] #почистила от неинформативных слов длиной менее 3\n",
    "    x = [[word   for word in line if word not in b] for line in x] #прошлась по списку стоп-слов\n",
    "    slova = slovar(x)\n",
    "    slova_more1 = [key for key in slova.keys() if slova[key] > 1] #список слов словаря, которые встречаются более 1 раза\n",
    "    return [[word   for word in line if word not in slova_more1] for line in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#чтение\n",
    "df = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')[['v2','v1']]\n",
    "\n",
    "#переименовка колонок\n",
    "df = df.rename(columns={'v1': 'class', 'v2':'text'})\n",
    "df = df[['text', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#проводим замену в классах\n",
    "df.loc[df['class'] == 'ham', 'class'] = '0'\n",
    "df.loc[df['class'] == 'spam', 'class'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = predobrabotka_new_new(df['text'], stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина короткого словаря - 4280\n"
     ]
    }
   ],
   "source": [
    "df_dictionary = slovar(df['text'])\n",
    "print('Длина короткого словаря -', len(df_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 7 (5 баллов). Представление в виде мешка слов** \n",
    "\n",
    "Реализуйте свою функцию, которая по списку текстов строит представление в виде мешка слов. На вход подаётся список текстов, а возвращает список имен признаков (т.е. слова по которым мы строим представление -- их порядок должен быть зафексирован) и numpy.array, который содержит вектора, каждая позиция которого -- число вхождений данного признака (слова) в текст.\n",
    "\n",
    "Сейчас мы реализовываем данную функцию в учебных целях, а вообще велосипед изобретать не стоит! Если вам нужно такое представление, то задействуйте модуль [sklearn.feature_extraction.text](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text). Импортируйте из него класс [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Создайте экземпляр класса с параметрами по умолчанию, а далее примените метод fit_transform для извлечения векторного представления текста. Чтобы получить список имён призков нужно воспользоваться методом get_feature_names. Проверте что ваша функция работает также (с точностью до перестановки признаков). \n",
    "\n",
    "Измерте скорость работы вашей и метода fit_transform. Для этого можно воспользоваться функцией time из модуля time. Постарайтесь максимально оптимизировать вашу функцию (время работы функции не должно привышать 10 с., за привышения лимита будут сняты баллы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def count_vectorizer(texts):\n",
    "    stop = stopwords.words('english')\n",
    "    x = [re.findall(r'\\w+', i.lower()) for i in texts]\n",
    "    x = [[word for word in line if word not in stop] for line in x]\n",
    "    x = [[word   for word in line if len(word) > 1] for line in x] #почистила от неинформативных слов длиной 1\n",
    "    s = set() # множество уникальных слов\n",
    "    for i in x:\n",
    "        s.update(i)  \n",
    "        \n",
    "    features_names = sorted(list(s)) #чтобы у нас была стабильность - сохраним слова в виде отсортированного list\n",
    "    \n",
    "    count_features = np.zeros((len(texts),len(features_names))) #матрица нулей, где мы будем хратить результаты\n",
    "    \n",
    "    for i in range(len(texts)): \n",
    "        for word in x[i]:#для каждой строчки мы смотрим все слова в ней\n",
    "            count_features[i][features_names.index(word)] += 1 #находим номер слова в словаре и увеличиваем индек в матрице\n",
    "    \n",
    "    features_names = np.array(features_names)\n",
    "    return features_names, count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#чтение\n",
    "df = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')[['v2','v1']]\n",
    "\n",
    "#переименовка колонок\n",
    "df = df.rename(columns={'v1': 'class', 'v2':'text'})\n",
    "df = df[['text', 'class']]\n",
    "\n",
    "#проводим замену в классах\n",
    "df.loc[df['class'] == 'ham', 'class'] = '0'\n",
    "df.loc[df['class'] == 'spam', 'class'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names, count_features1 = count_vectorizer(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%time features_names, count_features1 = count_vectorizer(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5572, 8536)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выведем число слов в первой строчке матрицы\n",
    "print(sum(count_features1[0]))\n",
    "#выведем размер матрицы\n",
    "count_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer = 'word',stop_words = stopwords.words('english'), lowercase = True)\n",
    "X_train_counts1 = count_vect.fit_transform(df['text']) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8536)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#как мы видим размеры библиотечной матрицы и матрицы, полученной нашей собственной функцией равны\n",
    "X_train_counts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-40e06ed76944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#а еще там 14 элементов в первой строчке, что значит, что скорее всего они равны с точностью до перестановок столбцов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_counts' is not defined"
     ]
    }
   ],
   "source": [
    "#а еще там 14 элементов в первой строчке, что значит, что скорее всего они равны с точностью до перестановок столбцов\n",
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 8 (5 баллов). Представление с использованием TfIdf** \n",
    "\n",
    "Задание аналогичное заданию 7, но теперь  признаки должны содержать значение tf-idf. \n",
    "\n",
    "Реализация должна быть на numpy.array, а не на списках!\n",
    "\n",
    "Аналогичная функция также содержится в [sklearn.feature_extraction.text](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tfidf_vectorizer(texts):\n",
    "    stop = stopwords.words('english')\n",
    "    x = [re.findall(r'\\w+', i.lower()) for i in texts]\n",
    "    x = [[word for word in line if word not in stop] for line in x]\n",
    "    x = [[word   for word in line if len(word) > 1] for line in x] #почистила от неинформативных слов длиной 1\n",
    "    s = set() # множество уникальных слов\n",
    "    for i in x:\n",
    "        s.update(i)  \n",
    "        \n",
    "    features_names = sorted(list(s)) #чтобы у нас была стабильность - сохраним слова в виде отсортированного list\n",
    "    \n",
    "    count_features = np.zeros((len(texts),len(features_names)),float) #матрица нулей, где мы будем хратить результаты\n",
    "    \n",
    "    for i in range(len(texts)): \n",
    "        for word in x[i]:#для каждой строчки мы смотрим все слова в ней\n",
    "            count_features[i][features_names.index(word)] += 1 / len(x[i]) #находим номер слова в словаре и увеличиваем индек в матрице\n",
    "    \n",
    "   \n",
    "    idf = np.array([sum([1 for j in count_features[:,i] if j > 0]) for i in range(count_features.shape[1])])\n",
    "    idf = np.log(count_features.shape[0] / idf)\n",
    "    \n",
    "    count_features = count_features * idf\n",
    "    features_names = np.array(features_names)\n",
    "    return features_names, count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names, count_features2 = tfidf_vectorizer(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.36674997,  1.00291828,  0.59885951,  1.44784299,  1.07348256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверим, \n",
    "count_features2[1][count_features2[1] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect2 = TfidfVectorizer(analyzer = 'word',stop_words = stopwords.words('english'), lowercase = True)\n",
    "X_train_counts2 = count_vect2.fit_transform(df['text']) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5427)\t0.272119513214\n",
      "  (0, 4448)\t0.408298856191\n",
      "  (0, 4255)\t0.523645807158\n",
      "  (0, 8264)\t0.431601036264\n",
      "  (0, 5454)\t0.546588171024\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 9 (10 баллов). Решение задачи классификации**\n",
    "\n",
    "Теперь с помощью наших представлений и [метода K ближайших соседей (KNN)](http://www.machinelearning.ru/wiki/index.php?title=KNN) ([нужный класс](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [полезная ссылочка](https://habrahabr.ru/post/149693/)) научимся вычислять спам.\n",
    "\n",
    "Пусть X -- вектора признаков (полученные с помощью CountVectorizer или TfidfVectorizer), y -- вектор ответов (в нашем случае колонка class в таблице). \n",
    "\n",
    "Разделите (X, y) на обучающую выворку (X_train, y_train) (70%) и на тестовую -- (X_test, y_test) (30%). Разделить выборку можно вручную, но лучше воспользоваться [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). \n",
    "\n",
    "Далее обучите классификатор на (X_train, y_train) -- это делается с помощью метода fit. Затем получите y_pred (результат классификации) на тесте X_test с помощью метода predict. После чего сравните получившийся результат y_pred и y_test (правельные метки классов) с помощью функции [accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html). \n",
    "\n",
    "Поиграйте с параметром n_neighbors у KNN -- добейтесь наилучшего результата классификации.\n",
    "\n",
    "Сравните качество классификации для представлений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92763157894736847"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_counts получена с помощью библиотечной функции\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_train_counts1, df['class'], test_size=0.3, random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_pred = neigh.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92822966507177029"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_features получена с помощью собственной функции\n",
    "X_train, X_test, y_train, y_test = train_test_split( count_features1, df['class'], test_size=0.3, random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_pred = neigh.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Теперь проверим всё для задания 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91626794258373201"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_counts получена с помощью библиотечной функции\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_train_counts2, df['class'], test_size=0.3, random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_pred = neigh.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91327751196172247"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_features получена с помощью собственной функции\n",
    "X_train, X_test, y_train, y_test = train_test_split( count_features2, df['class'], test_size=0.3, random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) \n",
    "y_pred = neigh.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
